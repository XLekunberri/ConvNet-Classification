{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy classification using convolutional networks\n",
    "#### Authors: Iker Ortiz and Xabier Lekunberri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(image, target_width=shape_x, target_height=shape_y, max_zoom=0.2):\n",
    "    \"\"\"Zooms and crops the image randomly for data augmentation.\"\"\"\n",
    "\n",
    "    # First, let's find the largest bounding box with the target size ratio that fits within the image\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    image_ratio = width / height\n",
    "    target_image_ratio = target_width / target_height\n",
    "    crop_vertically = image_ratio < target_image_ratio\n",
    "    crop_width = width if crop_vertically else int(height * target_image_ratio)\n",
    "    crop_height = int(width / target_image_ratio) if crop_vertically else height\n",
    "\n",
    "    # Now let's shrink this bounding box by a random factor (dividing the dimensions by a random number\n",
    "    # between 1.0 and 1.0 + `max_zoom`.\n",
    "    resize_factor = np.random.rand() * max_zoom + 1.0\n",
    "    crop_width = int(crop_width / resize_factor)\n",
    "    crop_height = int(crop_height / resize_factor)\n",
    "\n",
    "    # Next, we can select a random location on the image for this bounding box.\n",
    "    x0 = np.random.randint(0, width - crop_width)\n",
    "    y0 = np.random.randint(0, height - crop_height)\n",
    "    x1 = x0 + crop_width\n",
    "    y1 = y0 + crop_height\n",
    "\n",
    "    # Let's crop the image using the random bounding box we built.\n",
    "    image = image[y0:y1, x0:x1]\n",
    "\n",
    "    # Let's also flip the image horizontally with 50% probability:\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = np.fliplr(image)\n",
    "\n",
    "    # Now, let's resize the image to the target dimensions.\n",
    "    image = imresize(image, (target_width, target_height))\n",
    "\n",
    "    # Finally, let's ensure that the colors are represented as\n",
    "    # 32-bit floats ranging from 0.0 to 1.0 (for now):\n",
    "    return image.astype(np.float32) / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helping lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of names of images\n",
    "\n",
    "    list(df.index.values)\n",
    "\n",
    "#### List of names of solution values\n",
    "\n",
    "    list(df.columns.values)\n",
    "\n",
    "#### Value of specific label and column\n",
    "\n",
    "    df.at['100008', 'Class1.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of images to use\n",
    "n_img = 10000\n",
    "\n",
    "# Desired shape of input. Initial shape: 424x424\n",
    "shape_x, shape_y = 120, 120\n",
    "channels = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classes for images\n",
    "solutions = \"training/training_solutions.csv\"\n",
    "\n",
    "# Read data from imagesc\n",
    "df = pd.read_csv(solutions, index_col=0, header=0, nrows=n_img)\n",
    "\n",
    "# Set the indices as labels of type=str\n",
    "df.index = df.index.map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(os.path.join(\"training/images\", \"100008.jpg\"))[:, :, :channels]\n",
    "\n",
    "new_img = resize_image(img)\n",
    "\n",
    "plt.imshow(new_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the architecture of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"CNN\"):\n",
    "\n",
    "    \"\"\"Convolutional layers\"\"\"\n",
    "    # Layer 1\n",
    "    conv1 = tf.layers.conv2d(input_layer, filters=48, kernel_size=[5, 5], strides=[1, 1],\n",
    "                             padding='same', name='conv1', activation=tf.nn.relu)\n",
    "\n",
    "    pool1 = tf.layers.max_pooling2d(norm1, pool_size=[3, 3], strides=[3, 3], name='pool1')\n",
    "\n",
    "    # Layer 2\n",
    "    conv2 = tf.layers.conv2d(pool1, filters=96, kernel_size=[5, 5], strides=[1, 1],\n",
    "                             padding='same', name='conv2', activation=tf.nn.relu)\n",
    "\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=[2, 2], strides=[2, 2], name='pool2')\n",
    "\n",
    "    # Layer 3\n",
    "    conv3 = tf.layers.conv2d(pool2, filters=192, kernel_size=[3, 3], strides=[1, 1],\n",
    "                             padding='same', name='conv3', activation=tf.nn.relu)\n",
    "\n",
    "    # Layer 4\n",
    "    conv4 = tf.layers.conv2d(conv3, filters=192, kernel_size=[3, 3], strides=[1, 1],\n",
    "                             padding='same', name='conv4', activation=tf.nn.relu)\n",
    "\n",
    "    # Layer 5\n",
    "    conv5 = tf.layers.conv2d(conv4, filters=384, kernel_size=[3, 3], strides=[1, 1],\n",
    "                             padding='same', name='conv5', activation=tf.nn.relu)\n",
    "\n",
    "    # Layer 6\n",
    "    conv6 = tf.layers.conv2d(pool1, filters=96, kernel_size=[3, 3], strides=[1, 1],\n",
    "                             padding='same', name='conv6', activation=tf.nn.relu)\n",
    "\n",
    "    pool6 = tf.layers.max_pooling2d(conv6, pool_size=[3, 3], strides=[3, 3], name='pool6')\n",
    "\n",
    "    \"\"\"Fully conected layers\"\"\"\n",
    "    # Layer 7\n",
    "    full7 = tf.layers.dense(pool6, units=4*4, name='full7')\n",
    "\n",
    "    drop7 = tf.layers.dropout(full7, rate=0.5, name='drop7')\n",
    "\n",
    "    # Layer 8\n",
    "    full8 = tf.layers.dense(drop7, units=1*1, name='full8')\n",
    "\n",
    "    drop8 = tf.layers.dropout(full8, rate=0.5, name='drop8')\n",
    "\n",
    "    # Layer 8\n",
    "    logits = tf.layers.dense(drop8, units=1*1, name='out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
